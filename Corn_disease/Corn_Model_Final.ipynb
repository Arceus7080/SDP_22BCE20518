{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f18fa583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb 13 21:28:42 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 591.86                 Driver Version: 591.86         CUDA Version: 13.1     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   47C    P8              1W /   93W |    4776MiB /   6141MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            8516      C   ...da3\\envs\\plant_env\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           20296    C+G   ...Browser\\Application\\brave.exe      N/A      |\n",
      "|    0   N/A  N/A           21080    C+G   ...Browser\\Application\\brave.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ecfc3b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, MaxPooling2D, Flatten, Dense, Dropout, \n",
    "    BatchNormalization, Input,\n",
    "    RandomFlip, RandomRotation, RandomZoom, Rescaling\n",
    ")\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix,classification_report, f1_score\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9407b380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7316 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = image_dataset_from_directory(\n",
    "    'train',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    color_mode='rgb',\n",
    "    class_names=None,\n",
    "    shuffle=True,\n",
    "    seed = 123,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation='bilinear',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a14241b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1829 files belonging to 4 classes.\n",
      "Using 915 files for training.\n"
     ]
    }
   ],
   "source": [
    "validation_set = image_dataset_from_directory(\n",
    "    'valid',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    color_mode='rgb',\n",
    "    class_names=None,\n",
    "    shuffle=True,\n",
    "    seed = 123,\n",
    "    validation_split=0.5,\n",
    "    subset='training',\n",
    "    interpolation='bilinear',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "59444cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1829 files belonging to 4 classes.\n",
      "Using 914 files for validation.\n"
     ]
    }
   ],
   "source": [
    "test_set = image_dataset_from_directory(\n",
    "    'valid',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    color_mode='rgb',\n",
    "    class_names=None,\n",
    "    shuffle=True,\n",
    "    seed = 123,\n",
    "    validation_split=0.5,\n",
    "    subset='validation',\n",
    "    interpolation='bilinear',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cdfe74a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_', 'Corn_(maize)___Northern_Leaf_Blight', 'Corn_(maize)___healthy']\n"
     ]
    }
   ],
   "source": [
    "class_names = training_set.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cbe1944a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot: 1642\n",
      "Corn_(maize)___Common_rust_: 1907\n",
      "Corn_(maize)___Northern_Leaf_Blight: 1908\n",
      "Corn_(maize)___healthy: 1859\n"
     ]
    }
   ],
   "source": [
    "class_counts = np.zeros(len(class_names))\n",
    "\n",
    "for images, labels in training_set:\n",
    "    for label in labels:\n",
    "        class_counts[label.numpy()] += 1\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"{class_name}: {int(class_counts[i])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "808cdabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot: 215\n",
      "Corn_(maize)___Common_rust_: 226\n",
      "Corn_(maize)___Northern_Leaf_Blight: 238\n",
      "Corn_(maize)___healthy: 236\n"
     ]
    }
   ],
   "source": [
    "class_counts = np.zeros(len(class_names))\n",
    "\n",
    "for images, labels in validation_set:\n",
    "    for label in labels:\n",
    "        class_counts[label.numpy()] += 1\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"{class_name}: {int(class_counts[i])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fbdaff2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot: 195\n",
      "Corn_(maize)___Common_rust_: 251\n",
      "Corn_(maize)___Northern_Leaf_Blight: 239\n",
      "Corn_(maize)___healthy: 229\n"
     ]
    }
   ],
   "source": [
    "class_counts = np.zeros(len(class_names))\n",
    "\n",
    "for images, labels in test_set:\n",
    "    for label in labels:\n",
    "        class_counts[label.numpy()] += 1\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"{class_name}: {int(class_counts[i])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "77779782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(training_set)\n",
    "print(validation_set)\n",
    "print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "164623e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = Sequential([\n",
    "    RandomFlip(\"horizontal_and_vertical\"),\n",
    "    RandomRotation(0.2),\n",
    "    RandomZoom(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f26ff31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "training_set = training_set.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "validation_set = validation_set.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_set = test_set.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e3d126e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(224, 224, 3)),\n",
    "\n",
    "    data_augmentation,\n",
    "    Rescaling(1./255),\n",
    "\n",
    "    Conv2D(32, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(128, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(128, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5), \n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "81f5f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "50197669",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=(None, 224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "74b17cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_9 (Sequential)   (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " rescaling_4 (Rescaling)     (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 224, 224, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 224, 224, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 112, 112, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 112, 112, 64)      18496     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 112, 112, 64)     256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 56, 56, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 56, 56, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 56, 56, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 28, 28, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 28, 28, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 28, 28, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 14, 14, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               6422784   \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,667,076\n",
      "Trainable params: 6,665,860\n",
      "Non-trainable params: 1,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6d2955a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'Corn_custom_cnn_best_final.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [early_stop, reduce_lr, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f98648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "458/458 [==============================] - ETA: 0s - loss: 0.4306 - accuracy: 0.8397\n",
      "Epoch 1: val_accuracy improved from -inf to 0.64699, saving model to Corn_custom_cnn_best_final.keras\n",
      "458/458 [==============================] - 67s 124ms/step - loss: 0.4306 - accuracy: 0.8397 - val_loss: 1.4521 - val_accuracy: 0.6470 - lr: 1.0000e-04\n",
      "Epoch 2/30\n",
      "458/458 [==============================] - ETA: 0s - loss: 0.2662 - accuracy: 0.8976\n",
      "Epoch 2: val_accuracy improved from 0.64699 to 0.91475, saving model to Corn_custom_cnn_best_final.keras\n",
      "458/458 [==============================] - 55s 119ms/step - loss: 0.2662 - accuracy: 0.8976 - val_loss: 0.2255 - val_accuracy: 0.9148 - lr: 1.0000e-04\n",
      "Epoch 3/30\n",
      "458/458 [==============================] - ETA: 0s - loss: 0.2203 - accuracy: 0.9132\n",
      "Epoch 3: val_accuracy did not improve from 0.91475\n",
      "458/458 [==============================] - 54s 118ms/step - loss: 0.2203 - accuracy: 0.9132 - val_loss: 0.3251 - val_accuracy: 0.8656 - lr: 1.0000e-04\n",
      "Epoch 4/30\n",
      "458/458 [==============================] - ETA: 0s - loss: 0.1793 - accuracy: 0.9349\n",
      "Epoch 4: val_accuracy improved from 0.91475 to 0.93224, saving model to Corn_custom_cnn_best_final.keras\n",
      "458/458 [==============================] - 53s 116ms/step - loss: 0.1793 - accuracy: 0.9349 - val_loss: 0.1807 - val_accuracy: 0.9322 - lr: 1.0000e-04\n",
      "Epoch 5/30\n",
      "458/458 [==============================] - ETA: 0s - loss: 0.1622 - accuracy: 0.9393\n",
      "Epoch 5: val_accuracy did not improve from 0.93224\n",
      "458/458 [==============================] - 55s 120ms/step - loss: 0.1622 - accuracy: 0.9393 - val_loss: 0.1916 - val_accuracy: 0.9268 - lr: 1.0000e-04\n",
      "Epoch 6/30\n",
      "458/458 [==============================] - ETA: 0s - loss: 0.1417 - accuracy: 0.9459\n",
      "Epoch 6: val_accuracy did not improve from 0.93224\n",
      "458/458 [==============================] - 54s 118ms/step - loss: 0.1417 - accuracy: 0.9459 - val_loss: 0.2328 - val_accuracy: 0.9213 - lr: 1.0000e-04\n",
      "Epoch 7/30\n",
      "458/458 [==============================] - ETA: 0s - loss: 0.1278 - accuracy: 0.9526\n",
      "Epoch 7: val_accuracy did not improve from 0.93224\n",
      "458/458 [==============================] - 52s 113ms/step - loss: 0.1278 - accuracy: 0.9526 - val_loss: 0.2486 - val_accuracy: 0.9137 - lr: 1.0000e-04\n",
      "Epoch 8/30\n",
      "458/458 [==============================] - ETA: 0s - loss: 0.1185 - accuracy: 0.9578\n",
      "Epoch 8: val_accuracy improved from 0.93224 to 0.93880, saving model to Corn_custom_cnn_best_final.keras\n",
      "458/458 [==============================] - 53s 116ms/step - loss: 0.1185 - accuracy: 0.9578 - val_loss: 0.1452 - val_accuracy: 0.9388 - lr: 1.0000e-04\n",
      "Epoch 9/30\n",
      "458/458 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.9601\n",
      "Epoch 9: val_accuracy did not improve from 0.93880\n",
      "458/458 [==============================] - 56s 121ms/step - loss: 0.1095 - accuracy: 0.9601 - val_loss: 0.1446 - val_accuracy: 0.9388 - lr: 1.0000e-04\n",
      "Epoch 10/30\n",
      "458/458 [==============================] - ETA: 0s - loss: 0.1010 - accuracy: 0.9619\n",
      "Epoch 10: val_accuracy improved from 0.93880 to 0.95738, saving model to Corn_custom_cnn_best_final.keras\n",
      "458/458 [==============================] - 56s 123ms/step - loss: 0.1010 - accuracy: 0.9619 - val_loss: 0.1286 - val_accuracy: 0.9574 - lr: 1.0000e-04\n",
      "Epoch 11/30\n",
      "458/458 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.9627\n",
      "Epoch 11: val_accuracy did not improve from 0.95738\n",
      "458/458 [==============================] - 51s 112ms/step - loss: 0.1032 - accuracy: 0.9627 - val_loss: 0.1195 - val_accuracy: 0.9541 - lr: 1.0000e-04\n",
      "Epoch 12/30\n",
      "458/458 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 0.9682\n",
      "Epoch 12: val_accuracy did not improve from 0.95738\n",
      "458/458 [==============================] - 52s 113ms/step - loss: 0.0908 - accuracy: 0.9682 - val_loss: 0.2251 - val_accuracy: 0.9257 - lr: 1.0000e-04\n",
      "Epoch 13/30\n",
      "458/458 [==============================] - ETA: 0s - loss: 0.0883 - accuracy: 0.9660\n",
      "Epoch 13: val_accuracy did not improve from 0.95738\n",
      "458/458 [==============================] - 52s 115ms/step - loss: 0.0883 - accuracy: 0.9660 - val_loss: 0.5326 - val_accuracy: 0.8940 - lr: 1.0000e-04\n",
      "Epoch 14/30\n",
      "458/458 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 0.9688\n",
      "Epoch 14: val_accuracy improved from 0.95738 to 0.96721, saving model to Corn_custom_cnn_best_final.keras\n",
      "458/458 [==============================] - 51s 112ms/step - loss: 0.0861 - accuracy: 0.9688 - val_loss: 0.0899 - val_accuracy: 0.9672 - lr: 1.0000e-04\n",
      "Epoch 15/30\n",
      "458/458 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.9712\n",
      "Epoch 15: val_accuracy did not improve from 0.96721\n",
      "458/458 [==============================] - 52s 113ms/step - loss: 0.0779 - accuracy: 0.9712 - val_loss: 0.0975 - val_accuracy: 0.9607 - lr: 1.0000e-04\n",
      "Epoch 16/30\n",
      "458/458 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9748\n",
      "Epoch 16: val_accuracy did not improve from 0.96721\n",
      "458/458 [==============================] - 48s 104ms/step - loss: 0.0742 - accuracy: 0.9748 - val_loss: 0.1775 - val_accuracy: 0.9432 - lr: 1.0000e-04\n",
      "Epoch 17/30\n",
      "458/458 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.9698\n",
      "Epoch 17: val_accuracy did not improve from 0.96721\n",
      "458/458 [==============================] - 50s 110ms/step - loss: 0.0821 - accuracy: 0.9698 - val_loss: 0.0972 - val_accuracy: 0.9607 - lr: 1.0000e-04\n",
      "Epoch 18/30\n",
      "458/458 [==============================] - ETA: 0s - loss: 0.0716 - accuracy: 0.9725\n",
      "Epoch 18: val_accuracy did not improve from 0.96721\n",
      "458/458 [==============================] - 48s 106ms/step - loss: 0.0716 - accuracy: 0.9725 - val_loss: 0.1107 - val_accuracy: 0.9596 - lr: 1.0000e-04\n",
      "Epoch 19/30\n",
      " 98/458 [=====>........................] - ETA: 37s - loss: 0.0580 - accuracy: 0.9828"
     ]
    }
   ],
   "source": [
    "training_history = model.fit(\n",
    "    training_set,\n",
    "    validation_data=validation_set,\n",
    "    epochs=30,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60abd2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6ee3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìà Training history:\\n\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(training_history.history['accuracy'], label='Train', linewidth=2, marker='o')\n",
    "axes[0].plot(training_history.history['val_accuracy'], label='Validation', linewidth=2, marker='s')\n",
    "axes[0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(training_history.history['loss'], label='Train', linewidth=2, marker='o')\n",
    "axes[1].plot(training_history.history['val_loss'], label='Validation', linewidth=2, marker='s')\n",
    "axes[1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Model_acc_model_loss.png', dpi=800)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Final metrics\n",
    "best_val_acc = max(training_history.history['val_accuracy'])\n",
    "best_train_acc = max(training_history.history['accuracy'])\n",
    "final_val_loss = min(training_history.history['val_loss'])\n",
    "\n",
    "print(f\"\\nüìä FINAL METRICS:\")\n",
    "print(f\"   Best Train Accuracy: {best_train_acc:.4f} ({best_train_acc*100:.2f}%)\")\n",
    "print(f\"   Best Val Accuracy: {best_val_acc:.4f} ({best_val_acc*100:.2f}%)\")\n",
    "print(f\"   Best Val Loss: {final_val_loss:.4f}\")\n",
    "print(f\"   Target ‚â•98.5%: {'ACHIEVED ‚úÖ' if best_val_acc >= 0.985 else 'IN PROGRESS ‚è≥'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded4b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(training_history.history['accuracy']))\n",
    "print(max(training_history.history['val_accuracy']))\n",
    "print(min(training_history.history['loss']))\n",
    "print(min(training_history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5935a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dataset(model, dataset, class_names, dataset_name=\"Dataset\", cmap=\"Blues\"):\n",
    "    \n",
    "    print(f\"\\nüìä Evaluating model on {dataset_name}...\\n\")\n",
    "    pred_probs = model.predict(dataset, verbose=1)\n",
    "    y_pred = np.argmax(pred_probs, axis=1)\n",
    "\n",
    "    y_true = tf.concat([y for x, y in dataset], axis=0).numpy()\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"=\"*80)\n",
    "    print(f\"üìã CLASSIFICATION REPORT ({dataset_name.upper()})\")\n",
    "    print(\"=\"*80)\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
    "\n",
    "    # F1 Score\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    acc = (y_pred == y_true).mean()\n",
    "\n",
    "    print(f\"\\nüéØ Weighted F1 Score: {f1:.4f}\")\n",
    "    print(f\"üìä Overall Accuracy:  {acc:.4f}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(7,7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap,\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'Confusion Matrix - {dataset_name}', fontsize=16)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'confusion_matrix_{dataset_name.lower()}.png', dpi=800)\n",
    "    plt.show()\n",
    "\n",
    "    return f1, acc\n",
    "\n",
    "\n",
    "val_f1, val_acc = evaluate_dataset(model, validation_set, class_names, \"Validation\", \"Blues\")\n",
    "test_f1, test_acc = evaluate_dataset(model, test_set, class_names, \"Test\", \"Greens\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüîµ VALIDATION:\")\n",
    "print(f\"   Accuracy: {val_acc:.4f}\")\n",
    "print(f\"   F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "print(f\"\\nüü¢ TEST:\")\n",
    "print(f\"   Accuracy: {test_acc:.4f}\")\n",
    "print(f\"   F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "gap = abs(val_f1 - test_f1)\n",
    "\n",
    "if gap < 0.02:\n",
    "    print(f\"\\nGap: {gap:.4f} ‚úÖ Excellent generalization\")\n",
    "elif gap < 0.05:\n",
    "    print(f\"\\nGap: {gap:.4f} ‚ö†Ô∏è Acceptable\")\n",
    "else:\n",
    "    print(f\"\\nGap: {gap:.4f} ‚ùå Possible overfitting\")\n",
    "\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d75ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for image_batch, labels_batch in training_set.take(1):\n",
    "    for i in range(12):\n",
    "        ax = plt.subplot(3, 4, i + 1)\n",
    "        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels_batch[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650e1c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images_batch, labels_batch in test_set.take(1):\n",
    "    \n",
    "    first_image = images_batch[0].numpy().astype('uint8')\n",
    "    first_label = labels_batch[0].numpy()\n",
    "    \n",
    "    print(\"first image to predict\")\n",
    "    plt.imshow(first_image)\n",
    "    print(\"actual label:\",class_names[first_label])\n",
    "    \n",
    "    batch_prediction = model.predict(images_batch)\n",
    "    print(\"predicted label:\",class_names[np.argmax(batch_prediction[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103cf0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, img):\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)  \n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "    \n",
    "    predictions = model.predict(img_array)\n",
    "    \n",
    "    predicted_class = class_names[np.argmax(predictions[0])]\n",
    "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6335444",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "for images, labels in test_set.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        \n",
    "        predicted_class, confidence = predict(model, images[i].numpy())\n",
    "        actual_class = class_names[labels[i]] \n",
    "        \n",
    "        plt.title(f\"Actual: {actual_class},\\n Predicted: {predicted_class}.\\n Confidence: {confidence}%\")\n",
    "        \n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eb4da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('Corn_model_weights_final_vg.h5')\n",
    "model.save('Corn_custom_cnn_best_final_vg.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plant_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
